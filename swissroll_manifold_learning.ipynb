{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making the Swiss Roll data and setting up variables.**  \n",
    "\n",
    "Now we make the swiss roll with n_points, and with some noise. \n",
    "\n",
    "We also set a couple variables for Manifold learning, which are n_neighbors and n_components.\n",
    "* n_neighbors: number of neighbors to consider for each point\n",
    "* n_components: number of coordinates for the manifold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_points = 1000\n",
    "noise = 0\n",
    "X, color = datasets.samples_generator.make_swiss_roll(n_points, noise)\n",
    "\n",
    "# n_components = Set to 2 for this program because components \n",
    "#                beyond 2 will be difficult to visualize.\n",
    "n_neighbors = 10\n",
    "n_components = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Setting up the figure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x111b5b090>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the figure.\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "plt.suptitle(\"Manifold Learning with %i points, %i neighbors, %.2f noise\"\n",
    "             % (n_points, n_neighbors, noise), fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drawing the original Swiss Roll.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11288b750>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drawing the first subplot of the figure. \n",
    "#   .add_subplot(251) means 2x5 grid, 1st plot.\n",
    "#   X.shape is (n_points, 3). ax.scatter plots each dimension at a time.\n",
    "ax = fig.add_subplot(251, projection='3d')\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color)\n",
    "plt.title(\"Original Swiss Roll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up a function to apply manifold learning and plot result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def manifold_plot(raw_data, plot_loc, manifold_name, manifold_method):\n",
    "    t0 = time()\n",
    "    manifold_method = manifold_method\n",
    "    manifold_fit = manifold_method.fit_transform(raw_data)\n",
    "    t1 = time()\n",
    "    \n",
    "    ax = fig.add_subplot(plot_loc)\n",
    "\n",
    "    # Plot the 2 dimensions.\n",
    "    plt.scatter(manifold_fit[:, 0], manifold_fit[:, 1], c=color, cmap=plt.cm.Spectral)\n",
    "    plt.title(manifold_name + \"(%.2g sec)\" % (t1-t0))\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    plt.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up methods.** THERE HAS TO BE A BETTER WAY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_method = namedtuple('name_method', 'name method')\n",
    "\n",
    "LLE = name_method('LLE', \n",
    "        manifold.LocallyLinearEmbedding(n_neighbors, n_components, eigen_solver='auto', method='standard'))\n",
    "LTSA = name_method('LTSA', \n",
    "        manifold.LocallyLinearEmbedding(n_neighbors, n_components, eigen_solver='auto', method='ltsa'))\n",
    "HessianLLE = name_method('HessianLLE', \n",
    "        manifold.LocallyLinearEmbedding(n_neighbors, n_components, eigen_solver='auto', method='hessian'))\n",
    "ModifiedLLE = name_method('ModifiedLLE', \n",
    "        manifold.LocallyLinearEmbedding(n_neighbors, n_components, eigen_solver='auto', method='modified'))\n",
    "Isomap = name_method('Isomap', \n",
    "        manifold.Isomap(n_neighbors, n_components))\n",
    "MDS = name_method('MDS', \n",
    "        manifold.MDS(n_components, max_iter=100, n_init=1))\n",
    "SpectralEmbedding = name_method('SpectralEmbedding', \n",
    "        manifold.SpectralEmbedding(n_components=n_components, n_neighbors=n_neighbors))\n",
    "tSNE = name_method('tSNE', \n",
    "        manifold.TSNE(n_components=n_components, init='pca', random_state=0))\n",
    "\n",
    "methods = [LLE, LTSA, HessianLLE, ModifiedLLE, Isomap, MDS, SpectralEmbedding, tSNE]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now applying manifold_plot to the methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, method in enumerate(methods):\n",
    "    try:\n",
    "        manifold_plot(X, 252+i, methods[i].name, methods[i].method)\n",
    "    \n",
    "    # With high noise level, some of the models fail.\n",
    "    except:\n",
    "        pass\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation on the Manifold methods ##\n",
    "Much of this section is from scikit-learn website: http://scikit-learn.org/stable/modules/manifold.html#manifold\n",
    "  \n",
    "**Locally Linear Embedding** \n",
    " \n",
    "LLE seeks a lower-dimensional projection of the data which preserves distances within local neighborhoods. It can be thought of as a series of local Principal Component Analyses which are globally compared to find the best non-linear embedding. \n",
    "\n",
    "There are 4 methods in LLE: standard, local tangent space alignment (LTSA), hessian (HLLE), and modified (MLLE).\n",
    "- standard: seek a lower-dimensional projection of the data which preserves distances within local neighborhoods, kind of like PCA.\n",
    "- LTSA: for regularization, characterize the local geometry at each neighborhood via its tangent space.\n",
    "- HLLE: for regularization, hessian-based quadratic form at each neighborhood.\n",
    "- MLLE: use multiple weight vectors in each neighborhood.\n",
    "  \n",
    "  \n",
    "**Isomap**\n",
    "\n",
    "Isomap is kind of like an extension of PCA. Isomap seeks a lower-dimensional embedding which maintains geodesic distances between all points.\n",
    "  \n",
    "  \n",
    "**MDS**\n",
    "\n",
    "This method is often used for analyzing similarity/dissimilarity in data. It attempts to model similarity or dissimilarity data as distances in a geometric spaces.\n",
    "  \n",
    "  \n",
    "**SpectralEmbedding**\n",
    "\n",
    "Spectral Embedding finds a low dimensional representation of the data using a spectral decomposition of the graph Laplacian. \n",
    "  \n",
    "  \n",
    "**tSNE**\n",
    "\n",
    "t-SNE (TSNE) converts affinities of data points to probabilities. The affinities in the original space are represented by Gaussian joint probabilities and the affinities in the embedded space are represented by Studentâ€™s t-distributions. This allows t-SNE to be particularly sensitive to local structure and has a few other advantages over existing techniques: \n",
    "- Revealing the structure at many scales on a single map\n",
    "- Revealing data that lie in multiple, different, manifolds or clusters\n",
    "- Reducing the tendency to crowd points together at the center\n",
    "\n",
    "While Isomap, LLE and variants are best suited to unfold a single continuous low dimensional manifold, t-SNE will focus on the local structure of the data and will tend to extract clustered local groups of samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
